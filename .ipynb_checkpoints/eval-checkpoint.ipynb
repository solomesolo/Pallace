{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG:\n",
    "MODEL_PATH = 'models/model_360_epoch-2_kappa-0.653.pt'\n",
    "MODEL_PATH = 'models/model_512px_epoch-9_kappa-0.676.pt'\n",
    "MODEL_PATH = 'models/model_512px_epoch-17_kappa-0.651.pt'\n",
    "MODEL_PATH = 'models/model_512px_epoch-12_kappa-0.645.pt'\n",
    "MODEL_PATH = 'models/model_512px_epoch-11_kappa-0.624.pt'\n",
    "\n",
    "MODELS_FOLDER = 'models/'\n",
    "# LIST_ENSEMBLE_MODELS = ['model_360_epoch-2_kappa-0.653.pt']#, 'model_360_epoch-1_kappa-0.648.pt', 'model_360_epoch-3_kappa-0.64.pt']\n",
    "# LIST_ENSEMBLE_MODELS = ['model_512px_epoch-9_kappa-0.676.pt']#, 'model_360_epoch-3_kappa-0.64.pt']\n",
    "LIST_ENSEMBLE_MODELS = ['model_512px_epoch-9_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt']#, 'model_512px_epoch-6_kappa-0.651.pt', 'model_512px_epoch-17_kappa-0.651.pt']\n",
    "# LIST_ENSEMBLE_MODELS = ['model_360px_epoch-4_kappa-0.663.pt', 'model_360_epoch-2_kappa-0.653.pt']\n",
    "LIST_ENSEMBLE_MODELS = ['model_360px_epoch-4_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt'] #['model_360px_epoch-4_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt', 'model_360px_epoch-1_kappa-0.672.pt'] #['model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-4_kappa-0.676.pt']\n",
    "\n",
    "LIST_ENSEMBLE_MODELS = [MODELS_FOLDER+path for path in LIST_ENSEMBLE_MODELS]\n",
    "\n",
    "\n",
    "\n",
    "# INPUT_SIZE = 512 #360\n",
    "# CHANGE IT IN CONFIG FILE!\n",
    "\n",
    "BY_CATEGORIES = False\n",
    "\n",
    "single_model_14 = False#True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bohdan/work/ml/programs/anaconda3/envs/bone/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "  0%|          | 0/329 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_df shape: (329, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 249/329 [00:45<00:18,  4.32it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# from tensorboard_utils import *\n",
    "\n",
    "from model import PretrainedDensenet\n",
    "from read_data import Data\n",
    "from data_utils import *#MuraDataset\n",
    "from train import *\n",
    "from loss import Loss\n",
    "from visualize import see_samples, view_data_count\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "df = Data()\n",
    "valid_df = df.pallace_valid_df#valid_df\n",
    "\n",
    "\n",
    "print(\"valid_df shape:\", valid_df.shape)\n",
    "body_type = 'WRIST'\n",
    "# valid_df = valid_df[valid_df['BodyPart']==body_type]\n",
    "\n",
    "    \n",
    "if not single_model_14:\n",
    "    val_dataset = MuraDataset(df=valid_df, is_train=False)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=1, num_workers=0, shuffle=False)#, pin_memory=True)\n",
    "\n",
    "# if not single_model_14:\n",
    "#     model = PretrainedDensenet()\n",
    "#     model.to(device)\n",
    "# #     model.load_state_dict(torch.load(MODEL_PATH))\n",
    "#     model.eval()\n",
    "\n",
    "valid_df['study'] = valid_df['FilePath'].apply(lambda x: '/'.join(x.split('/')[:-1]))\n",
    "print(\"unique studies:\", valid_df['study'].nunique())\n",
    "\n",
    "original_valid_df = valid_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if single_model_14:\n",
    "    from best_single import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval single \n",
    "def eval_trained_model(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        list_outputs = []\n",
    "        list_labels = []\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images, labels = Variable(images.to(device)), Variable(labels.to(device))\n",
    "            labels = labels.view(-1,1)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            # save output and labels for kappa_score\n",
    "            outputs = output.cpu().numpy() # np.where(output.cpu().numpy() >= 0.5, 1, 0)\n",
    "            list_outputs.extend(outputs.tolist())\n",
    "    list_outputs = [el[0] for el in list_outputs]\n",
    "    return list_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval single \n",
    "def eval_single14():\n",
    "    list_outputs = []\n",
    "    for FilePath in tqdm(valid_df['FilePath'].values):\n",
    "        image = cv2.imread(FilePath)\n",
    "        output = predict_image(image)\n",
    "        list_outputs.append(output)\n",
    "    return list_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INIT MODELS\n",
    "list_models = []\n",
    "for model_path in LIST_ENSEMBLE_MODELS:\n",
    "    model = PretrainedDensenet()\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    list_models.append(model)\n",
    "    print(\"model_path:\", model_path)\n",
    "    \n",
    "\n",
    "15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = original_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Predicting for validation dataset with size of {0}*{0}\".format(str(INPUT_SIZE)))\n",
    "\n",
    "# predict all models\n",
    "list_models_outputs = []\n",
    "for model in list_models:\n",
    "    list_outputs = eval_trained_model(model)\n",
    "    list_models_outputs.append(list_outputs)\n",
    "#     print(\"list_outputs:\", list_outputs)\n",
    "\n",
    "list_outputs_global = []\n",
    "\n",
    "print(len(list_models_outputs[0]))\n",
    "CNT = 0\n",
    "for output_idx in range(len(list_models_outputs[0])):\n",
    "    CNT += 1\n",
    "    output = np.array([list_output_single[output_idx] for list_output_single in list_models_outputs]).mean()\n",
    "    if CNT < 20:\n",
    "        print(\"list_models:{} , output:{}\".format([list_output_single[output_idx] for list_output_single in list_models_outputs], output))\n",
    "    \n",
    "\n",
    "    list_outputs_global.append(output)\n",
    "    \n",
    "list_outputs = list_outputs_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average prediction for the whole study\n",
    "\n",
    "valid_df['single_pred'] = list_outputs\n",
    "\n",
    "valid_df_grouped = valid_df.groupby('study', as_index=False)['single_pred'].agg(np.mean)\n",
    "valid_df = valid_df.merge(valid_df_grouped, left_on='study', right_on='study',\n",
    "          suffixes=('', '_mean'))\n",
    "\n",
    "valid_df_study = valid_df.drop_duplicates('study').reset_index()\n",
    "avg_pred_label = [1 if x >=0.5 else 0 for x in valid_df_study['single_pred_mean'].to_list()]\n",
    "valid_df_study['avg_pred_label'] = avg_pred_label\n",
    "\n",
    "print(\"valid_df_study.shape:\", valid_df_study.shape)\n",
    "valid_df_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_outputs = valid_df_study['avg_pred_label'].to_list()\n",
    "list_labels = valid_df_study['Label'].to_list()\n",
    "\n",
    "print(\"LEN list_outputs:\", len(list_outputs))\n",
    "\n",
    "# -------------------------- metrics\n",
    "# Kappa statistics\n",
    "kappa_score = cohen_kappa_score(list_outputs, list_labels)\n",
    "# AUC ROC\n",
    "auc_roc_score = roc_auc_score(list_outputs, list_labels)\n",
    "# accuracy\n",
    "accuracy = accuracy_score(list_outputs, list_labels)\n",
    "\n",
    "print (f\"\\nKappa score : {kappa_score} \\nAUC ROC score : {auc_roc_score} \\nAccuracy : {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa score : 0.28829630228655756 \n",
    "# AUC ROC score : 0.6342547262182723 \n",
    "# Accuracy : 0.6747720364741642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble 3 epochs 360px\n",
    "# Kappa score : 0.686122081972251 \n",
    "# AUC ROC score : 0.8518781192540058 \n",
    "# Accuracy : 0.8465387823185988\n",
    "# ​\n",
    "# 2 worse models\n",
    "# Kappa score : 0.6823768682331293 \n",
    "# AUC ROC score : 0.8512197982641334 \n",
    "# Accuracy : 0.8448707256046706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_512px_epoch-9_kappa-0.676.pt\n",
    "# Kappa score : 0.6600182609040849 \n",
    "# AUC ROC score : 0.8350018709881696 \n",
    "# Accuracy : 0.8331943286071727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 360*360 input with models from 512*512 ensemble ['model_512px_epoch-9_kappa-0.676.pt', 'model_512px_epoch-6_kappa-0.651.pt', 'model_512px_epoch-17_kappa-0.651.pt']\n",
    "# Kappa score : 0.6715555910652529 \n",
    "# AUC ROC score : 0.8479111846968039 \n",
    "# Accuracy : 0.8398665554628857\n",
    "\n",
    "\n",
    "# 512*512 input with models from 512*512 ensemble ['model_512px_epoch-9_kappa-0.676.pt', 'model_512px_epoch-6_kappa-0.651.pt', 'model_512px_epoch-17_kappa-0.651.pt']\n",
    "# Kappa score : 0.7051445158190557 \n",
    "# AUC ROC score : 0.8606135504507124 \n",
    "# Accuracy : 0.8557130942452044\n",
    "\n",
    "# 512*512 input for ['model_512px_epoch-9_kappa-0.676.pt'] solo\n",
    "# Kappa score : 0.6907244840400353 \n",
    "# AUC ROC score : 0.8502719609940088 \n",
    "# Accuracy : 0.8482068390325271\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 360*360  ['model_360px_epoch-4_kappa-0.663.pt']\n",
    "# just one epoch after 'model_360_epoch-2_kappa-0.653.pt'\n",
    "# Kappa score : 0.6921554748263383 \n",
    "# AUC ROC score : 0.8518042129063517 \n",
    "# Accuracy : 0.8490408673894912\n",
    "\n",
    "# ['model_360px_epoch-4_kappa-0.663.pt', 'model_360_epoch-2_kappa-0.653.pt']\n",
    "# Kappa score : 0.6953444499489687 \n",
    "# AUC ROC score : 0.8541138947684978 \n",
    "# Accuracy : 0.8507089241034195\n",
    "\n",
    "#  ['model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt']\n",
    "#     Kappa score : 0.7030767435306977 \n",
    "# AUC ROC score : 0.8609971120231038 \n",
    "# Accuracy : 0.8548790658882403\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 360*360 ['model_512px_epoch-9_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt']\n",
    "# Kappa score : 0.6929455149728543 \n",
    "# AUC ROC score : 0.8553775209409568 \n",
    "# Accuracy : 0.8498748957464554\n",
    "\n",
    "# ['model_360px_epoch-4_kappa-0.676.pt']\n",
    "# Kappa score : 0.7042136229399962 \n",
    "# AUC ROC score : 0.8640922576040861 \n",
    "# Accuracy : 0.8557130942452044    \n",
    "\n",
    "# ['model_360px_epoch-4_kappa-0.676.pt', 'model_512px_epoch-9_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt']\n",
    "# Kappa score : 0.7041098274388862 \n",
    "# AUC ROC score : 0.8645279451731064 \n",
    "# Accuracy : 0.8557130942452044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['model_360px_epoch-4_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt']\n",
    "\n",
    "# Kappa score : 0.7164305416248746 \n",
    "# AUC ROC score : 0.8692091490598952 \n",
    "# Accuracy : 0.8615512927439533\n",
    "\n",
    "# ['model_360px_epoch-4_kappa-0.676.pt', 'model_360_epoch-2_kappa-0.653.pt', 'model_360px_epoch-8_kappa-0.672.pt', 'model_360px_epoch-7_kappa-0.67.pt']\n",
    "# Kappa score : 0.7201412985001978 \n",
    "# AUC ROC score : 0.869758965005203 \n",
    "# Accuracy : 0.8632193494578816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(list_outputs).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
